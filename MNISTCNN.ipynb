{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Convolutional Neural Network Model with Keras in Tensorflow\n",
    "\n",
    "In this exercise, we will implement a convolutional neural network used for image classification with four hidden layers, using stochastic gradient descent. We will once again work with the MNIST data set, a famous collection of images used for handwriting recognition. It contains labelled images of handwritten numbers from 0 to 9. Using Keras, we will fit a CNN to classify these images. We will carry out the following steps: \n",
    "\n",
    "1. Import and clean the data\n",
    "2. Construct the convolutional neural network\n",
    "3. Train the model\n",
    "4. Evaluate the model\n",
    "\n",
    "To get started, let us import the libraries we need.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the Data Set and Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mnist data set comes preloaded in Keras. The `load_data()` function returns the data set split into training and test subsets. The cell below loads the data set and contains training and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# The mnist data set comes preloaded in Tensorflow    \n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "# Create training and test sets\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created a function `plot_imgs` to help us visualize the training data. Execute the two code cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the training data\n",
    "def plot_imgs(images, labels=None):\n",
    "    subplots_x = int(math.ceil(len(images) / 5))\n",
    "    plt.figure(figsize=(10,2*subplots_x))\n",
    "    for i in range(min(len(images), subplots_x*5)):\n",
    "        plt.subplot(subplots_x,5,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        plt.imshow(images[i], cmap=plt.cm.binary)\n",
    "        if labels is not None:\n",
    "            plt.xlabel(labels[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize some example training images\n",
    "plot_imgs(x_train[:5], y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training points: 60000 \n",
      "Number testing points : 10000\n"
     ]
    }
   ],
   "source": [
    "print('Number training points:',len(x_train), '\\nNumber testing points :',len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras downloads the images raw with pixel values between 0 and 255. We must normalize them to be between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize pixel values\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Converting datasets of shape (num_points, 28, 28) to (num_points, 28, 28, 1)\n",
    "x_train, x_test = x_train[..., np.newaxis], x_test[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Define Model Structure\n",
    "\n",
    "Constructing a hidden layer in a convolutional neural network requires composing a 2D convolution, followed by a batch normalization and then followed by a transition function. The code cell below uses the `Sequential` class to create a CNN with four hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 16)        160       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 16)        64        \n",
      "_________________________________________________________________\n",
      "re_lu (ReLU)                 (None, 26, 26, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 24, 24, 32)        128       \n",
      "_________________________________________________________________\n",
      "re_lu_1 (ReLU)               (None, 24, 24, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 22, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 22, 22, 64)        256       \n",
      "_________________________________________________________________\n",
      "re_lu_2 (ReLU)               (None, 22, 22, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_3 (ReLU)               (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 99,402\n",
      "Trainable params: 98,922\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# layer 1 (specifies initial input layer as well):\n",
    "conv_1= keras.layers.Conv2D(16, 3, strides=(1, 1), input_shape=(28, 28, 1), activation=None)\n",
    "batchNorm_1 =  keras.layers.BatchNormalization()\n",
    "relu_1 = keras.layers.ReLU()                             \n",
    "model.add(conv_1)\n",
    "model.add(batchNorm_1)\n",
    "model.add(relu_1)\n",
    "\n",
    "# layer 2:\n",
    "conv_2= keras.layers.Conv2D(32, 3, strides=(1, 1), activation=None)\n",
    "batchNorm_2 =  keras.layers.BatchNormalization()\n",
    "relu_2 = keras.layers.ReLU()\n",
    "model.add(conv_2)\n",
    "model.add(batchNorm_2)\n",
    "model.add(relu_2)\n",
    "\n",
    "# layer 3:\n",
    "conv_3= keras.layers.Conv2D(64, 3, strides=(1, 1), activation=None)\n",
    "batchNorm_3 = keras.layers.BatchNormalization()\n",
    "relu_3 = keras.layers.ReLU()\n",
    "model.add(conv_3)\n",
    "model.add(batchNorm_3)\n",
    "model.add(relu_3)\n",
    "\n",
    "# layer 4:\n",
    "conv_4= keras.layers.Conv2D(128, 3, strides=(1, 1), activation=None)\n",
    "batchNorm_4 =  keras.layers.BatchNormalization()\n",
    "relu_4 = keras.layers.ReLU()\n",
    "model.add(conv_4)\n",
    "model.add(batchNorm_4)\n",
    "model.add(relu_4)\n",
    "\n",
    "# pooling layer\n",
    "pooling_layer = keras.layers.GlobalAveragePooling2D()\n",
    "model.add(pooling_layer)\n",
    "\n",
    "# output layer\n",
    "output_layer = keras.layers.Dense(10, activation=None)\n",
    "model.add(output_layer)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Define the Optimization Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Train the Model\n",
    "\n",
    "We can fit the model on the training data. Since there are 60,000 training data points and nearly 100,000 parameters to fit, this may take a while to run even though we are only choosing to use 10 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 145s 77ms/step - loss: 0.3367 - accuracy: 0.9179\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0992 - accuracy: 0.9731\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0752 - accuracy: 0.9784\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 144s 77ms/step - loss: 0.0621 - accuracy: 0.9820\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 142s 76ms/step - loss: 0.0548 - accuracy: 0.9838\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0497 - accuracy: 0.9851\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0469 - accuracy: 0.9859\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0433 - accuracy: 0.9869\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0397 - accuracy: 0.9880\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 143s 76ms/step - loss: 0.0379 - accuracy: 0.9882\n",
      "Elapsed time: 1432.83s\n"
     ]
    }
   ],
   "source": [
    "M = 10 # Number of epochs\n",
    "\n",
    "t0 = time.time() # start time\n",
    "\n",
    "history = model.fit(x_train, y_train, epochs=M)\n",
    "\n",
    "t1 = time.time() # stop time\n",
    "\n",
    "print('Elapsed time: %.2fs' % (t1-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Evaluate the Network\n",
    "\n",
    "After all that training, let's see how we did. To do this, we'll compute the model's loss and accuracy on the hold out test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.0677681490778923 Accuracy:  0.9799000024795532\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Loss: ', str(loss) , 'Accuracy: ', str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll make some predictions on the test set and see for ourselves how accurate they are. The code cell below will display the first 5 images in the test set `x_test`, and below each image, it will print the predicted digit. How well did we do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions on first 5 test images:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "logits = model.predict(x_test)\n",
    "predictions = logits.argmax(axis = 1)\n",
    "\n",
    "# Examine individual predictions\n",
    "print('Predictions on first 5 test images:')\n",
    "plot_imgs(np.squeeze(x_test * 255, axis=-1)[:5], predictions[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
