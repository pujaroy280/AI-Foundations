{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement Decision Trees for Iris Classification\n",
    "\n",
    "We are going to continue working with the iris data set and will build a Decision Tree to classify iris flowers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "\n",
    "Before you get started, you need to import a few libraries. You can do this by executing the following code. Remember, run code in a cell by selecting the cell, holding the shift key, and pressing enter/return.\n",
    "\n",
    "We will import the scikit-learn `DecisionTreeClassifier`, the `train_test_split` function for splitting the data into training and test sets, and the metric `accuracy_score` to evaluate our model. In this exercise we will be performing a k-fold cross validation on the model, and so we will also import the scikit-learn function for running cross validaton."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load the Iris Data Set\n",
    "\n",
    "Next we will load the data from the iris data set and store it in a dataframe named `dfiris`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiris = pd.read_csv('Iris_Data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create labeled examples from our data set for the training phase\n",
    "\n",
    "Let's extract variables from our data set to create labeled examples. This time, every example will be using all of the features in the iris dataset.\n",
    "\n",
    "The code cell below carries out the following steps:\n",
    "\n",
    "* Extracts all features from `dfiris` and assign it to the variable `X`. \n",
    "* Creates the `species` label from `dfiris` and assigns it to the variable `y`.\n",
    "* Prints the values of `X` and `y`\n",
    "\n",
    "Execute the code cell below and inspect the results. You will see that we have 150 labeled examples. Each example contains four features and one label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     sepal_length  sepal_width  petal_length  petal_width\n",
      "0             5.1          3.5           1.4          0.2\n",
      "1             4.9          3.0           1.4          0.2\n",
      "2             4.7          3.2           1.3          0.2\n",
      "3             4.6          3.1           1.5          0.2\n",
      "4             5.0          3.6           1.4          0.2\n",
      "..            ...          ...           ...          ...\n",
      "145           6.7          3.0           5.2          2.3\n",
      "146           6.3          2.5           5.0          1.9\n",
      "147           6.5          3.0           5.2          2.0\n",
      "148           6.2          3.4           5.4          2.3\n",
      "149           5.9          3.0           5.1          1.8\n",
      "\n",
      "[150 rows x 4 columns]\n",
      "            species\n",
      "0       Iris-setosa\n",
      "1       Iris-setosa\n",
      "2       Iris-setosa\n",
      "3       Iris-setosa\n",
      "4       Iris-setosa\n",
      "..              ...\n",
      "145  Iris-virginica\n",
      "146  Iris-virginica\n",
      "147  Iris-virginica\n",
      "148  Iris-virginica\n",
      "149  Iris-virginica\n",
      "\n",
      "[150 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "x = dfiris[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']]\n",
    "y = dfiris['species'].to_frame()\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create Training & Test Data Sets\n",
    "\n",
    "Now that we have specified examples, we will need to split them into a training set and a test set.\n",
    "\n",
    "We will refer to the training feature vectors as `x_train` with labels `y_train`. \n",
    "\n",
    "Our testing vectors are `x_test` with labels `y_test`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fit a Decision Tree with the Training Set\n",
    "\n",
    "The code cell below:\n",
    "\n",
    "1. Creates a DecisionTreeClassifier() object and assignss the result to the variable model.\n",
    "\n",
    "2. Calls the .fit() method on model to fit the model to the training data. The first argument should be `x_train` and the second `y_train`. \n",
    "\n",
    "3. Uses the .predict() method on model with the argument `x_test` to use the fitted model to predict values for the testing data. Store the outcome in the variable `y_pred`. We will compare these values to `y_test` later.\n",
    "Execute the code cell below and notice how the different flowers were classified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "tree_model = DecisionTreeClassifier(random_state=0)\n",
    "\n",
    "# Train the model using the training sets\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions using the test set\n",
    "pred = tree_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Check the accuracy of your model\n",
    "\n",
    "Execute the code cell below to see the accuracy score of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "score = accuracy_score(y_test, pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Perform k-Fold Cross-Validation on the Model\n",
    "\n",
    "The code cell below uses scikit-learn's `cross_val_score` function to perform cross-validation on the model.\n",
    "\n",
    "You will recall that k-fold cross-validation splits a training data set into equally sized subsets, or folds (k). We train and test 'k' times, such that each time, we train on k-1 folds and test on 1 fold. Therefore, every fold will have a chance to serve as a test set. We then average the resulting accuracies obtained on each of the k iterations to detemine the accuracy of the model.\n",
    "\n",
    "The `cross_val_score` function requires that you pass your model as an arugment using the `estimator` parameter. It  allows you to specify the value for `k` using the parameter `cv`. It returns `k` number of accuracy scores, one for each training/test iteration. \n",
    "\n",
    "We will perform a k-fold cross-validation using 4 folds. Execute the code cell below and inspect the results. \n",
    "\n",
    "You'll notice that the four resulting accuracy scores are good, and the standard deviation among the scores are low, indicating that our model performs well. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracies for the four training/test iterations:\n",
      "[0.96666667 0.9        0.93333333 0.93333333]\n",
      "The mean accuracy score across the four iterations:\n",
      "0.9333333333333333\n",
      "The standard deviation of the accuracy score across the four iterations:\n",
      "0.02357022603955158\n"
     ]
    }
   ],
   "source": [
    "all_accuracies = cross_val_score(estimator=tree_model, X=x_train, y=y_train, cv=4)\n",
    "\n",
    "# Print the accuracy scores\n",
    "print('Accuracies for the four training/test iterations:')\n",
    "print(all_accuracies)\n",
    "\n",
    "# Print the average using the mean() method\n",
    "print('The mean accuracy score across the four iterations:')\n",
    "print(all_accuracies.mean())\n",
    "\n",
    "# Print the standard deviation of the accuracy scores using the std() method to see the degree of variance.\n",
    "print('The standard deviation of the accuracy score across the four iterations:')\n",
    "print(all_accuracies.std())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Perform a Grid Search on the Model\n",
    "\n",
    "For this decision tree, we used the default hyperparameters. If we had wanted to optimize the hyperparameters for that method, we could have used the `GridSearchCV` function within scikit-learn, which searches over different combinations of possible hyperparameter values to find the set that results in the best cross-validation (CV) score. You can find the names of the `DecisionTreeClassifier` hyperparameters in the [scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html). You can also find more information on `GridSearchCV` in the corresponding [scikit-learn documentaton](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html).\n",
    "\n",
    "The code cell below demonstrates how to use the `GridSearchCV` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "# Import the GridSearchCV function\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Dictionary of different hyperparameters to try.\n",
    "# GridSearchCV will choose which max_depth hyperparameter is best\n",
    "hyperparameters = {'max_depth': [2,3,4,5,6,7,8]}\n",
    "\n",
    "# Run a Grid Search with 4-fold cross-validation using our decision tree model\n",
    "grid = GridSearchCV(tree_model, param_grid=hyperparameters, cv=4)\n",
    "\n",
    "grid.fit(x_train, y_train)\n",
    "\n",
    "# Print best hyperparameter to use\n",
    "print(grid.best_params_)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
