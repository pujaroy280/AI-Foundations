{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Deep Averaging Neural Network Model with Keras in Tensorflow\n",
    "\n",
    "In this project, you will implement a Deep Averaging Network for sentiment classification. \n",
    "\n",
    "This will involve the following steps:\n",
    "\n",
    "1. Load the data set\n",
    "2. Create a \"featurizer\"\n",
    "3. Construct the deep averaging neural network\n",
    "4. Train the model\n",
    "5. Evaluate the model\n",
    "\n",
    "Use the other Neural Network implementations that you have seen this week as guides for completing this exercise.\n",
    "\n",
    "To get started, let us import the libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load the Data Set\n",
    "\n",
    "We will use the <a href=https://www.cs.jhu.edu/~mdredze/datasets/sentiment/>multi-domain sentiment</a> data set created by Professor <a href=https://www.cs.jhu.edu/~mdredze/>Mark Dredze</a> for our project. This data set contains product reviews taken from Amazon.com from many product types. The product reviews are labeled as positive or negative. In this exercise, we will only consider book reviews. To make things simpler, we also created a dictionary `vocab` that contains words that will be considered when constructing the word embedding for the deep averaging network. Run the following two cells to load the data and see a positive and a negative review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Reviews:  1787\n",
      "Number of Test Reviews:  200\n",
      "Number of Words in the Vocabulary:  4380\n"
     ]
    }
   ],
   "source": [
    "review_train = pd.read_csv('review_train.csv')\n",
    "review_test = pd.read_csv('review_test.csv')\n",
    "vocab = np.load('vocabulary.npy', allow_pickle=True).item()\n",
    "\n",
    "# class 1 == Positive reviews\n",
    "# class 0 == Negative reviews\n",
    "label_meaning = ['Negative', 'Positive']\n",
    "\n",
    "print('Number of Training Reviews: ', review_train.shape[0])\n",
    "print('Number of Test Reviews: ', review_test.shape[0])\n",
    "print('Number of Words in the Vocabulary: ', len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Positive Training Review: \n",
      "\n",
      " This was perhaps the best of Johannes Steinhoff's books, since it does not  deal with his own stellar yet tragic WW II and post war career. The  insights of the average person living in Germany are of great importance to  both social and military historians alike. Steinhoff offered this  collective testament as a warning to all of us regarding war and the rise  of a dictator. As Johannes said in an interview, &quot;It is always the  civilians who suffer the most, yet are remembered the least.&quot\n",
      "\n",
      "A Negative Training Review: \n",
      "\n",
      " I got to page 26 and gave up.  Lockes writings lack focus and are void of humour.  I read as much as I could with patience until it became clear this book was simply someone rambling on about nothing.  Save your money for something worth reading\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print some training reviews\n",
    "print('A Positive Training Review: \\n\\n', review_train.iloc[0]['review'])\n",
    "print('A Negative Training Review: \\n\\n', review_train.iloc[-1]['review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Word Embeddings from our Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We wll create a featurizer to convert the input text to feature vectors. We will use a function from <code>sklearn</code> called <code>CountVectorizer</code> that creates word embeddings for us. It creates a featurizer that takes in a vocabulary and return a **bag of words featurizer** based on the vocabulary. Using the returned featurizer, you can convert a sentence into a bag of words feature vector. See the code cell below for an example on how to use the <code>CountVectorizer</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "# Create a simple vocabulary\n",
    "simple_vocab = {'learn': 0, 'machine': 1, 'learning': 2, 'teach': 3}\n",
    "\n",
    "# Create a simple sentence that will be converted into bag of words features\n",
    "simple_sentence = ' I learn machine learning to teach machine how to learn.'\n",
    "\n",
    "# Create a featurizer by passing in the vocabulary to CountVectorizer\n",
    "simple_featurizer = CountVectorizer(vocabulary = simple_vocab)\n",
    "\n",
    "# Call simple_featurizer.transform to transform the sentence to its bag of word features\n",
    "output = simple_featurizer.transform([simple_sentence]).toarray()\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have gotten the array `[[2, 2, 1, 1]]` as output.\n",
    "This means that the sentence has 2 occurences of 'learn', 2 occurences of 'machine', \n",
    "1 occurence of 'learning' and 1 occurence of 'teach'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, we will use <code>CountVectorizer</code> to generate a featurizer based on the vocabulary we provided in the `vocab` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the given vocab to generate bag of words featurizer\n",
    "bow_featurizer = CountVectorizer(vocabulary = vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Training and Test Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, we will use the featurizer to convert the training reviews and test reviews into bag of word representations that we can use to train and test our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the reviews to bow representation and tf Tensor\n",
    "x_train = bow_featurizer.transform(review_train['review'].values).toarray() \n",
    "y_train = review_train['label'].values.flatten()\n",
    "x_test = bow_featurizer.transform(review_test['review'].values).toarray()\n",
    "y_test = review_test['label'].values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.  Define Model Structure\n",
    "\n",
    "Like we did in the previous projects, we will use the `Sequential` class to create our neural network structure. But performing the averaging step is tricky in Keras, as it does not give us control over how forward propagation is performed. The solution to this problem is to define our own averaging layer in Tensorflow and Keras, which can be included in `Sequential` when creating the model. We will do this by creating a class `KerasAveragingLayer` in the code cell below. Make sure to execute the cell below in order to use the class in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our own averaging layer class in Keras\n",
    "class KerasAveragingLayer(keras.layers.Layer):\n",
    "    def __init__(self, vocab_size, embedding_size=32):\n",
    "        super().__init__()\n",
    "        self.embeds = self.add_weight(\n",
    "            'embeds', shape=[vocab_size, embedding_size]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        return tf.matmul(x, self.embeds) / tf.reduce_sum(x, axis=1, keepdims=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below we define the model structure using the `Sequential` class and our custom `KerasAveragingLayer` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "input_layer = keras.layers.InputLayer(len(vocab)) # define input layer\n",
    "model.add(input_layer)\n",
    "averaging_layer = KerasAveragingLayer(len(vocab), embedding_size=32)\n",
    "model.add(averaging_layer)\n",
    "output_layer = keras.layers.Dense(2, activation=None)\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Define the Optimization Function\n",
    "\n",
    "In the code cell below, create a stochastic gradient descent `SGD` optimizer with a learning rate of 5 and assign the result to a variable called `optimizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(learning_rate=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testoptimizer\n",
    "try:\n",
    "    print(testoptimizer(optimizer))\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Define the loss function\n",
    "\n",
    "In the code cell below, create a `SparseCategoricalCrossentropy` loss function with the argument `from_logits=True`, and assign the result to a variable called `loss_fn`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testlossfn\n",
    "try:\n",
    "    print(testlossfn(loss_fn))\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. Compile the Model\n",
    "\n",
    "In the code cell below, package the network architecture with the optimizer and the loss function using the `.compile()` method. Include the `metrics` parameter with the value `accuracy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testmodel\n",
    "try:\n",
    "    print(testmodel(model))\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we will define our own callback class to output information from our model while it is training. Make sure you execute the code cell below so that it can be used in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProgBarLoggerNEpochs(tf.keras.callbacks.Callback):\n",
    "    \n",
    "    def __init__(self, num_epochs: int, every_n: int = 50):\n",
    "        self.num_epochs = num_epochs\n",
    "        self.every_n = every_n\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if (epoch + 1) % self.every_n == 0:\n",
    "            s = 'Epoch [{}/ {}]'.format(epoch + 1, self.num_epochs)\n",
    "            logs_s = ['{}: {:.4f}'.format(k.capitalize(), v)\n",
    "                      for k, v in logs.items()]\n",
    "            s_list = [s] + logs_s\n",
    "            print(', '.join(s_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the code cell below, run the `.fit()` method on the model to learn parameters from the training data and save the output to variable `history`. In addition to passing in the training data `x_train` and `y_train` as arguments, specify the following parameters:\n",
    "\n",
    "* set `epochs` to equal M\n",
    "* set `steps_per_epoch` to equal 5\n",
    "* set `batch_size` to equal 128\n",
    "* set `verbose` to 0\n",
    "* set `callbacks` to a list containing our logger function`ProgBarLoggerNEpochs(M, every_n=100)`  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell\n",
    "\n",
    "<i>Note: a self-check will not accompany this exercise</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/ 1000], Loss: 0.5441, Accuracy: 0.7234\n",
      "Epoch [200/ 1000], Loss: 0.2345, Accuracy: 0.9203\n",
      "Epoch [300/ 1000], Loss: 0.1033, Accuracy: 0.9669\n",
      "Epoch [400/ 1000], Loss: 0.0840, Accuracy: 0.9734\n",
      "Epoch [500/ 1000], Loss: 0.0285, Accuracy: 0.9969\n",
      "Epoch [600/ 1000], Loss: 0.0129, Accuracy: 1.0000\n",
      "Epoch [700/ 1000], Loss: 0.0088, Accuracy: 1.0000\n",
      "Epoch [800/ 1000], Loss: 0.0066, Accuracy: 1.0000\n",
      "Epoch [900/ 1000], Loss: 0.0040, Accuracy: 1.0000\n",
      "Epoch [1000/ 1000], Loss: 0.0040, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "M = 1000 # number of epochs\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    steps_per_epoch = 5,\n",
    "    batch_size = 128,\n",
    "    epochs=M,\n",
    "    verbose=0, # disable the default progress bar\n",
    "    callbacks=[ProgBarLoggerNEpochs(M, every_n=100)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model will likely train quickly, reaching 100% accuracy in a few-hundred epochs. We can plot the training losses to check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcHHWd//HXp3uO3AlJBhJIIIRTVM4IoqwiKHLtqisquqvosj9+67Gr+3PdBV11dVVUXK/V5Vhx1dVVV7w4RUTkEgghEiQJIReQhIRMrjmSubr78/ujq2qqZ3p6amq6Z5Lp9/Px6Ee6q75d9a1pqE99b3N3REREADLjnQEREdl/KCiIiEhEQUFERCIKCiIiElFQEBGRiIKCiIhEFBRERCSioCAiIhEFBRERiTSMdwZGau7cub5o0aLxzoaIyAHlscce2+HuLcOlO+CCwqJFi1i2bNl4Z0NE5IBiZs8mSafqIxERiSgoiIhIREFBREQiCgoiIhJRUBARkYiCgoiIRBQUREQkoqAgE8ZT29pZ9syu8c6GyAHtgBu8JjKU8796PwDPfP6icc6JyIFLJQUREYkoKIiISERBQUREIgoKIiISUVAQEZGIgoKIiEQUFEREJKKgICIiEQUFERGJKCiIiEhEQUFERCIKCiIiElFQEBGRiIKCiIhEFBRERCSioCAiIhEFBRERiSgoiIhIREFBREQiNQsKZrbQzO4xs1VmttLMPlgmzdlm1mZmjwevT9QqPyIiMryGGh47B3zY3Zeb2XTgMTO7y91XDUh3v7tfXMN8iIhIQjUrKbj7VndfHrzvAFYDh9XqfCIiMnpj0qZgZouAU4BHyuw+08xWmNkdZvbisciPiIiUV8vqIwDMbBrwU+BD7t4+YPdy4Ah37zSzC4FfAMeUOcYVwBUAhx9+eI1zLCJSv2paUjCzRooB4Qfu/rOB+9293d07g/e3A41mNrdMuhvcfYm7L2lpaalllkVE6lotex8ZcCOw2t2/PESaeUE6zOz0ID87a5UnERGprJbVR68E3gn80cweD7Z9FDgcwN2vAy4B3mtmOaALuNTdvYZ5EhGRCmoWFNz9AcCGSfMN4Bu1yoOIiIyMRjSLiEhEQUFERCIKCiIiElFQEBGRiIKCiIhEFBRERCSioCAiIhEFBRERiSgoiIhIREFBREQiCgoiIhJRUBARkYiCgoiIRBQUREQkoqAgIiIRBQUREYkoKIiISERBQUREIgoKIiISUVCQCcfdxzsLIgcsBQWZcBQTRNJTUJAJRzFBJD0FBZlwVH0kkp6Cgkw4Cgki6SkoyISjgoJIegoKMuG4ygoiqdUsKJjZQjO7x8xWmdlKM/tgmTRmZl83s3Vm9oSZnVqr/Ej9UElBJL2GGh47B3zY3Zeb2XTgMTO7y91XxdJcABwTvM4Arg3+FRGRcVCzkoK7b3X35cH7DmA1cNiAZG8AvudFDwOzzGx+rfIk9UElBZH0xqRNwcwWAacAjwzYdRiwKfZ5M4MDh8iIqE1BJL2aBwUzmwb8FPiQu7enPMYVZrbMzJa1trZWN4My4aikIJJeTYOCmTVSDAg/cPeflUmyBVgY+7wg2FbC3W9w9yXuvqSlpaU2mZUJQzFBJL1a9j4y4EZgtbt/eYhkNwPvCnohvRxoc/ettcqT1AeNaBZJr5a9j14JvBP4o5k9Hmz7KHA4gLtfB9wOXAisA/YB76lhfqROKCSIpFezoODuDwA2TBoH3l+rPEh9UkFBJD2NaJaJR0FBJDUFBZlw1CVVJD0FBZlwVH0kkp6Cgkw4igki6SkoyISjLqki6SkoyISjkCCS3rBBwcy+aGYzzKzRzO42s1Yz+8uxyJxIGiooiKSXpKRwXjBn0cXAM8DRwEdqmSmR0VDvI5H0kgSFcIDbRcBP3L2thvkRGT3FBJHUkoxovtXMngK6gPeaWQvQXdtsiaSnmCCS3rAlBXe/EngFsMTd+4C9FBfHEdkvqU1BJL0kDc1vAfrcPW9m/wx8Hzi05jkTSUltCiLpJWlT+Li7d5jZWcBrKU6HfW1tsyWSnkoKIuklCQr54N+LgBvc/TagqXZZEhkdxQSR9JIEhS1mdj3wNuB2M2tO+D2RcaERzSLpJbm5vxW4E3i9u+8BZqNxCiIiE1KS3kf7gPXA683sA8DB7v7rmudMJCUVFETSS9L76IPAD4CDg9f3zexva50xEREZe0kGr10OnOHuewHM7AvAQ8C/1zJjIiIy9pK0KRj9PZAI3ldce1lkPKn6SCS9JCWF/wIeMbOfB5/fSHGsgsh+SYPXRNIbNii4+5fN7HfAWcGm97j7H2qaK5FRUElBJL0hg4KZzY59fCZ4RfvcfVftsiUiIuOhUknhMYqDQ8P2g/D5y4L3i2uYL5HUVFAQSW/IoODuR45lRkSqRSOaRdLTdBUiIhKpWVAws2+b2XYze3KI/WebWZuZPR68PlGrvEh9UTlBJL0kXVLT+g7wDeB7FdLc7+4X1zAPUodUeySS3rBBYUAvpFBHsArbkNz9PjNblDJfIqOgqCCSVpLqo+VAK/A0sDZ4/4yZLTez00Z5/jPNbIWZ3WFmLx7lsUREZJSSBIW7gAvdfa67zwEuAG4F3gf8xyjOvRw4wt1PojiP0i+GSmhmV5jZMjNb1traOopTSj1Q9ZFIekmCwsvd/c7wQzBt9pnu/jDQnPbE7t7u7p3B+9uBRjObO0TaG9x9ibsvaWlpSXtKqROKCSLpJQkKW83sn8zsiOD1j8ALZpYFCmlPbGbzzMyC96cHedmZ9ngiIZUURNJL0vvoHcAn6a/eeTDYlqW4KltZZvZD4GxgrpltDo7RCODu1wGXAO81sxzQBVzqGnUkIjKukkyItwMYalGddRW+9/ZhjvsNil1WRapKs6SKpJekS+qxwD8Ai+Lp3f2c2mVLJD2VN0XSS1J99BPgOuBblC62IyIiE0yShuacu1/r7kvd/bHwVfOcSd1Y+Xwb53/1Pjp7clU5nkoKIuklCQq3mNn7zGy+mc0OXzXPmdSNL/5qDU9t6+DRjdVZokNtCiLpJak+uiz49yOxbVpPQarGghU7qnUzV0lBJL0kvY+0roLUVLSKk27mIuOu0nKc57j7b83sz8vtd/ef1S5bUk8sLCqIyLirVFJ4NfBb4E/L7HNAQUGqqlolBZU4RNKrtBznJ4N/3zN22Rk/bV19TGtuIJvRU+tYG7gIuIiMnySD15qBNzN48Nqna5etsdWXL3DSp37NO844nM+96aXjnZ26U+3aI/U+EkkvSZfUXwJvAHLA3thrwujJFef1++UftoxzTupbtaa+UvWRSHpJuqQucPfza56TcZQvFO8iGTPO+dLvOPdFB/Oxi06I9m/evY+W6c00N2THK4sTXLGoUK17uWKCSHpJSgq/N7MJXaeSywczgBts2LGX/7x/Y8m+s75wDx/60ePjlLuJLxqnoLu5yLhLUlI4C3i3mW0Eeig+1rm7n1jTnNWQu3PrE1vZ3tHD5WcdSS5WUhgo3Hf36u1jmsd6Uu2mfc3ALpJekqBwQc1zMYae2tbO+V+9P/pcKHj0pFqu41EhvMGoU9IYqFKbQlWOIlKfKg1em+Hu7UDHGOan5pY/u6fk82dvXx29r1RSUEyoHVUfiew/KpUU/ge4GHiM4sNX/L54wM59NNJhCIUwKCgq1IxVOeQquIikN2RDs7tfHPx7pLsvDv4NXwdkQIDypYHQzr290fvj/vkO2vb1xUoKigq1Vr17uaKCSFpJeh9hZgeZ2elm9qrwVeuM1UrSJ/6eXIEnn2+LSgqS3qPP7Kr4d6x29ZFKCiLpDRsUzOyvgfuAO4FPBf/+S22zVTsjmXwtm7H+koIKCqk8sHYHb7nuIb71wIYh01R76mwRSS9JSeGDwMuAZ939NcApwJ7KX9k/5QvOv966KnH6xqxFA9sUE9LZtHsfAOu3Dz0IvuptClU9mkh9SRIUut29G4rzILn7U8Bxtc1WbSzduIu2rr7E6TMWCwoqKqQSjRZP0MKv6iOR8ZdknMJmM5sF/AK4y8x2A8/WNlu1sXtf7/CJBsipTWFUwoFk2UqPH1H1UXXPKSIjl2TltTcFb//FzO4BZgK/qmmuamQkpQQoPuWGg9dUUEgnLClkK/wB+1de081cZLxVrD4ys6yZPRV+dvd73f1mdx/5I/d+YG9PLnr/8YtPqJCyqC/v5PKD2xQ+c+sqPjOCtol6Fvz5ElUfVYtCi0h6FYOCu+eBNWZ2+BjlZ8w0ZYe/ScVLCnHfemAj33pgY5lvyECFCvNKhardXqMCh0h6SdoUDgJWmtlSYusouPufVfqSmX2b4ojo7e7+kjL7DfgacCGwD3i3uy8fQd5HLH6Db6xYyV2UKxRiXVJVf5RGPmpTSFJ9NAYZEpGKkgSFj6c89neAbwDfG2L/BcAxwesM4Nrg35qJNxpPbR7+0nN5j+rE27r66M0VaGpINN5PAvlEJYXqnlPjHUTSS3KHuzBoS4heFJ/uK3L3+4BdFZK8AfieFz0MzDKz+cmynU58VO0hMyYNmz5X6A8KAE+/MPTcgF/7zVpe/rm7R5fBCShR76MwbbVu5ooJIqklCQqvK7OtGtNpHwZsin3eHGwbxMyuMLNlZrastbU19QlzJUGhedj0+YKTKxQSHfsrv3mabe3dqfOWRL7go+qhs2tvL4uuvI171ozd2hDh+kXJeh9V55yKCSLpDRkUzOy9ZvZH4DgzeyL22gg8MXZZBHe/wd2XuPuSlpaW1MeJP/UfNmvysOm/ec86bn1ia+rzVdtRH72d93zn0dTff3JLGwA33j92jeRhm0Kl3kdhe43aFETG33BTZ98BXA1cGdve4e6VqoWS2gIsjH1eEGyrmXhJoSGb4aIT53NbhZv+qq3trNraXsssjdjv1qQvKYXGss08Ue+j4N/qDV6r0oFE6tCQQcHd24A24O01OvfNwAfM7EcUG5jb3L2mj+X5AaOTZ01uHNH3cwXn+nvXVzNLY2o87pVJeh+FqjV4TQ3NIukl6X2Uipn9EDgbmGtmm4FPAo0A7n4dcDvFBut1FLukvqdWeQmFA9F+f+U5AByaoAoprjdX4Oo7nqqYxt3VfTUmSUkhmuZC93KRcVezoODuFUsYXnwsfH+tzl9OvlBg5uTGKBgce8j0kv0PXXUOa1/o5F3fXlr2+/ER0UMpOCQYF1c3omkuKnRpCGdJLTdQMA0FF5H06qrTfd6dhlg1xmtfdDBffPOJ0ef5Mydz1tFzh/x+kkbepL2VxsN4zC0UNTQnKD3lq1Z9JCJp1VdQKHhJ3baZ8daXLSxJk8kYh84cfgxDpXPs78ayeqtQGL5NIcxOtf50mlhPJL26Cgq5fGlJYSj3/uNrUp+jWkHB3fnJsk109earcjwYnyfo8M9RqaSQidoUdDMXGW91FRTyBSeboMI/SeAIPbmljbdd/1DJOQC2tnWNPIMxD67byUdueoLP3l6cjbWaN8yxbPJI0hMoalOoVkCtylFE6lNdBYVcwWnIlL/ky886Mno/kuqVGx/YyCMb+4dt5ArOwxt2cubVv+WWFc9H21s7evjULSvpyydrc2jvLq79sLOzOEt52hLIik17WLMtmJ5jHO+WSYJa1WreFBVEUqtZ76P90cA2hdAzn78o1fHcnUNnlbY/FAoe3YSXbtzFn550KACfumUltz6xlTMXz+G8F88b9tiFAQ20aVaAy+ULvOGbD2IGG6/uv8ZqNSns6OxhWnMDkxqzw6atlP3+NgWNUxAZb3VWUihUnIOnnItPnF/SQynuf5dtGtT9MRcLPLmC8+93r2XRlbfRkytE20L3Pt3K79fvKHvs/rWhi5/T3DB37i2WMmpVVb/kM7/hXTeW7747UKUsVDsoiEh6dRMUCgXnzpUvsKbCTKflfOMdp/LWly0sO1fSb1ZvH3Sz29bezU2PbQaK4yKuDUZA54Jqo3g10GXfXso7/vORsuf1AQ20aUoKY9ETaukzlWc8Ca+jUvVReI19+SqVFBRbRFKrm6DQ2Tv8wLNKesu0BWzatY9dnaUrk/6f7y7j8U17gOKNPLxBhe0Uv171QqLz9VcfBZ+rEBTGs1ql0o06XPAop6AgMu7qJih0942ua2dvbnBQeGpbBz9etqlkW1hlA8UbeXgjDp+Ub1nxfNmeSe7OjQ9sZHfw/agrZyZ9SWHgzTEKUCM+UnphFpJUDe3PA/9E6kX9BIXe4g3nQ689JtX3ywWF4fTFSgrxW2JfbvANcsXmNv711lV85KYVwOA5g1KVFIa4EY/H3ExJcl+uNFarc4lIeXUTFLqCksLA+Y6SOmPx7BF/J5/vDwrxe3q5e3LYVXXPvr4gfTASuIptCtWsVkk6bqL/+odOH+4bTfVRPD8aBCeSXt10SQ2DwuQE3ScBrrnkxJIn6m++41Q27+7i9V+9L/E5c2Wqj4YSnim8QfYvTlPcnqbReKgbcTXKCSPNTqXLD/clHcMxXH4UEkTSq5+gEEwXkaRPPcBblpTOiTS1uYHj5o2slOHuZW+GSerXw5vcD5duYtXWDv70xJEvXz24oXlkzv2333H6kXO4+s9fWiZ/SY82fFAMA+doeh+pO6tIddRNUAgbmic3JQsK1eD034jj96xyVUFhoaQ/fX+aFZv2sCLo0TQSo71Rrm/dy/rWvWWDQtKSS3+X1OHTjKakED++4oNIenXXppC0+qgaCu7RzT1+Ey0UvEzDcek6xZUalj123Irnr2FnnpEGnEoxJNyXG1X1UfwEigoiadVNUDh+3nT++aIXcciM5jE7p3v/7akn198lNlfwQT1tlgbzJ4XpK9WknHn1b3nVNfcMe/6hex8N+9Xhjz3CRoXKYyRGX32k0oFIddRN9dHilmksbpk26uP8+9tP4bld+7jmzjXDpnX6b1Zdff1BIF8mKHzhV8VlPlds2kNfvlCxJLCtvTtRXgf3PqrenTNpKWTMqo9iQUcBQiS9ugkK1RJOcHfPU9tZ9uzuimnzsTtnfPBcruAVxz3ccN8GGquwpufAIND/afTHTrpKWpLeV1GX1FFMy6HeRyLVUTfVR9V27osOGTZN/MYfDwr5QqFiUGjt6KEa47iGGqcwXPVRR3cfe/b1VkyTtPooTFax8qgqXVJVUhCpBpUUUpo9tXHYNPEbf1dJUKg8QrohYyNqdN2zr5c12zo4Y/Gcku0Dn+YHPq2vb+2kMZPh8DlTSra/4vO/paO78lxRSRuaw3SV0od70owaj46hGTJEqkIlhZQuOW3hsGl2xCbLi5cUdnT2RFNpl9OQzdA3gqqUd317KW+74eFBgWRgvf/AQ577b/eWbbAeLiBAbbqkjuYJv6RNQRVIIqkpKKSUzRhNweye8W6uv/3wq6P3W/b0T3zXHWtoft8Plpc8FQ98gm/MjqyksPL5dqC0Tn7jjr2DJt6LP62PpqoGRlJ9FJYUhk4TddsdRVQoaVNQTBBJTdVHoxDO6vnqY1v41cptnP/ieYl7OPXm49VJpXexbMZGVJUSNhH05gvRiO3zvnLvoC6eHku/e2/lNoPhJK8+Cs89fPXRaAbbaUSzSHWopDAK4Q0vHPswkt4z8eqjgd9rzGZG1Gc/WqQmdsxy34+XSEbT0wdGXlKoXH00fGliOCUjmtMfRqTuKShUwcEzius0D9erJz5wrrdCUChuG76kEN3kg/OGgWCoUkZ4gzYb/YI2SZ/MPQoKlbqkMmyapOcZ7XFE6l1Ng4KZnW9ma8xsnZldWWb/u82s1cweD15/Xcv81MqcqU3A8L3/45PxxW/cP1++uSRdLu+JSgphMAnPG7YT7Btilbl4nBntgjbxOFZ5So7B6QelCf4dzfKhY7DyqEhdqFlQMLMs8E3gAuAE4O1mdkKZpD9295OD17dqlZ9aam4s/hmHKynEn86v+O/Hovcf/+XKknR9+UKihuawCio8b/h5b2/5VeaikgJW1eqjB9fvGDLdmFUfqdJIpCpqWVI4HVjn7hvcvRf4EfCGGp5vzP3kb87kC29+abTGcFi3f+NlSzjr6LmD0iddEvQb96xLdNMOA4cRLnwfBIWe8iWF+OC10VYfxYPClKah+ysUopLC8A3No6n2Ue8jkeqoZVA4DIgvYLw52DbQm83sCTO7yczKdv43syvMbJmZLWttba1FXlN52aLZvO1lh0efwyf2c190CGcc2b9SW7DMMnOmNSU+dpKg8Hc/epydnT3ReYcLCoWShubRVh/1H6u5Yej/jJLN5jr8ALekxwCVGkRGY7wbmm8BFrn7icBdwHfLJXL3G9x9ibsvaWlpGdMMJtHf3ttff9QUu1FObS4+Sc+fOZmb/ubMRMdMUn1039OtfPa21f29j4LvDN3QXPz3/rU7+I971pfsa+3oYdGVt/HzP2wu883B4iWFSm0BSUoK+UIVqo9UUhCpiloGhS1A/Ml/QbAt4u473b0n+Pgt4LQa5qdmontQrE0hHhSmBUGh4M5RCccxJO2Suq61Myop9OacXL4w5E06fILu7Mnxq5XbSvY9u3MvAN976NlE543f5CsNOkvSphANcBtFVFDpQKQ6ahkUHgWOMbMjzawJuBS4OZ7AzOJrTP4ZsLqG+akZjxpw+4XtDABTgtXe3PtLDZU0Zi1x9U6+4NF5f7j0OY7+2B08u2tf2bSV7rlhz6j4yOtQV5mG63hBptLNPMngtXw1qo9UUhCpipoFBXfPAR8A7qR4s/9fd19pZp82sz8Lkv2dma00sxXA3wHvrlV+aqm/Abd89VF4o509talkezkXnzifvryPqCE4PO/NK54HYM22jiHyOfyNuadMY/inblnJwxt28rGf/3FQekg2hUWlNOGljqb6qGSW1PSHEal7NZ3mwt1vB24fsO0TsfdXAVfVMg9j4U+OmcvB05v5m1cvjrbFRyxng5bmUw+fNeyxmhuywfeT9VRyH9wVdqjqo0pP9GF+d5WZMntrWzeX3vAwAJ9540swsxG0KSSoPqpCSUGlA5HqGO+G5glhzrRmln7stbz40JnRtm2xyejecPKhXPsXp/KuMxcBcN1fDt100hAEkEef2c2xhwzf/lBwHzRobqg6/kpP4mHj9J59fYP2zZrSP0142NYRr96q2N00wWjlqPpoNG0KGtEsUhUKCjVyxpH9axtkzLjgpfPJBDf8Pzlm8BiGUENsxbUtu7uGTBdPs3vAjbxczyV3r3jzjk/QN1BTrH0k7OFUzZJCPkEV03C08ppIdSgo1Mirjm3hPa9cBDCoHSE+1fZAYUkBoHGY9geAjjJjEsqt1dCbL1Rcw6HSrKzxMRO5qKSQtPdRgjTVqD5CUUGkGjR1dg1tby/2tj2qZWrJ9kzGuOGdp5ErOO/7wfKSfdlMfyD481MW0JA1fr9+B09uaU983r09g5/6H96wq2wjMsDVd6zm+ns3DHm8+NoLvWVKCpWqazxBd9OqlBS08ppIVSgo1NCHzzuWKU1Zzjl+8HrO5714Hsue2TVoe3yZz6suPJ7GbIav3PX0iIJCuQnxdnT00D1EaaBSQIDSKTHCtoSSkkKFG3KYrNII7aqMaC7pfaSigkhaCgo1tLhlGte85aQh93cOqPq58oLjaZnWP712ONahMTvc/Kulfr9+Z9lzDVVSGE68Ubkv51x/73pufWJrtC1Jm0KlNP0lher0PlI7s0h6CgrjaM7U5pLPJy6YSWtHz6B0DdnKbQvZjA077XRnT67swLQkVj3fX0rpKxS4+o6nSvZXupn3lxSGPndY0tCIZpHxp4bmcfTSBTO59W/PYnHQ5tDckCkZCR0qty1ucmOWTIXCRGPWiiWFhGMfBnq+rTt6X25t58pdUocvKYTBYDRP+Op9JFIdCgrj7CWHzYyqjHr6CiW9j0LhLKRD9VpqGiKYhKY1N9DZnavY+yipciOtK1YNFfp7K+ULXrZROqw+qtRDaTglbQqKCiKpKSjsB9555hEALJw9JVraM27BQZMB6BqiTaCju69iUJja3BBUH6UrKcT1jrCkEAaRfMF51Rfv4U3/8fvB36/yiGZVJYmkpzaF/cDFJx7KhS8pDm5bOHvKoP3Dzazal3cas+VvhGZBSWEUbQpx5UsKlfJW3NnTV2DLni627Bk8IK8aXVI1ilmkOhQU9hOZWLXR8o+/ruSp/tBZk6P33/ur09nR2cP/+98VJd8fqmooY8b0ScXqo4G9nYayuGUqG1r3lt1Xtk2hwt08LFnsLjOnUigftSlollSR8abqo/3Q7KlNJYEgnFBvenMDrzq2hT8/dcGg78ya3DhoG0DWLKo+6ugePK9ROeGkfOWMtKE5LFnsG2LdaOgPCsP1oKqkZO6j1EcREZUUDhBLP3ruoHaDw2ZN5qIT52PAY8/uZufe/qfxj154PJ+7/SlmTG5kWnMDz+3cR0d3spJCpZ5M5W7ulRqIoyVCywyoi75fhZXXRvNdEemnoHCAGNgAveIT59HYYExpKv6En7l1Fcue3Q3Aiw+dwSuOKk6615vLM31SA+3duZKgUUm83SBsjwjt6Bw8jiJJ9dFQ60bDwJ5DXrIuRVKu0WsiVaGgcICaOaW0uugfXn8cLdOb+auzjqQxm4me0N//mqPJFbzszXwo8SAwpSlb8jmczymuUrVPmI9Ky4sOXLBnhAO4o++FFBJE0lNQmCAmNWb5v68+KvrcmM3wzOcvAmDd9g7+55HnmD21ia6+POu2dwLwxpMP5cH1O8uOog6FT/HhqOnNuwcv9TlUTPjmPesS9XgaOA13tlL91RDi3VBVUBBJT0GhDhx98HQevPIcAFo7eli3vZPj501n2qQGNrTu5cktbXzxzqd4ISgFLDhoMn35Ats7eqJeTZ9540u45s41bNgxuFdSuYbmzp4c19y5JlH+4kFlX2+OpoamkV6i2hREqkS9j+pMy/RmzjxqDgdNbaIxm+G4edN582kLePCfzuGn7z0TgDeechizpxZvzIcFvaBmTGrk+HnTeWJz26Bjfv3utZx9zT089uwuenMF3J22rmQ9naC0pHDyp+/i/rWtI76ueGAq10NKRJJRSUGA4qR7px0xm3s/cjZHzJnKT5ZtAuBrl57CTY9t4nUnHEJ3X77sDKzt3Tnau3O8+dqHAPjI64/j4OnNg9LFbWvr5qfLN/PZQNyFAAANbUlEQVS+s4+KqozC4PCf92/k5IWzmD6pfDfbsmIlhfaEvaxEZDCVFKTEEXOKk/P9x1+cxpffehLHzZvOxy46gaaGDG8+bfD4iHKuuXMNH7npiSH3b+/o5vLvPso1d65h9dYOevMF5kztrzK67+lWLv/OssR5bu/u4/LvPhp9TjoeQ0QGU1CQsubNnFR2kNw1l5zI37/2WBqzxqUvW8jNH3jlsMcauB7E6Z+9m5XBdNwXfv1+oDhteNzSMgsQDeWmZZtL2hTau1RSEElL1UcyIm9ZshCA97/mKLIZw8z4/ZXnMG/GJP64pY03fPNBAGZNaWTPvuIT+0kLZkVjKIayZNFsfrN6e8m2RVfexpffehLP7+niS79+mic/9XqmNZf+J9vdl+fTt66KPs+bMYn27j4KBS+ZOkREkrEDbSKxJUuW+LJlyasWZGzl8gUKXpzOe/lzu/nSnWv42qWn8O0HN3Lu8QdzyXUPlf3eL9//yiigVHL/P76GBQdNxsz41ZNb2b2vj6t+9sdo/ymHz+IPz+0BYN1nL6AhGLPR3Zdn+qRG1r7QwVEt02jr6uMXj2/hrlUv8P3LzxgygGzcsZe2rj5OXjgrxV9DZP9hZo+5+5Jh0ykoyFjqyeW57YmtLG6ZxidvXsmKTcUb+OpPn09HTx93/HEba7d38P2Hn0t1/E9cfEJJyaGcN558KLc8sTVq2L7xsiWc+6LSdbTdnfO+ch9rgzEd4ZgPKPZuaghKSSIHiv0iKJjZ+cDXgCzwLXf//ID9zcD3gNOAncDb3P2ZSsdUUJhY7l/byqMbd/H/zjtu0L4X2rvZvHsfvTmnMWvcsuJ5fvjoJnrLzAh78sJZnLF4Nleefzw3PrCRz9y2ekT5aMwa7nD0wdNomd7MrClN3LLi+Wj/fR95Dc2NGQw4/XN38w/nHctlr1hEc0OWbMZKBtxtb++mZXqzgobsV8Y9KJhZFngaeB2wGXgUeLu7r4qleR9worv/jZldCrzJ3d9W6bgKCvXN3enJFXhqWwf/u2wTrR09nHfCIVFbBxSrsH62fAtvOvUwHli7g0zG2NDayfLn9nD8vOn05Qt89Tdrq563GZMaOHzOFJ7c0s5bTlvA/FmTeaGtm3kzJ7Fp1z5edWwLmYxx/b3rOWH+DJY/t5vr33kaU5oayJjx0IYdXPCS+UBx/YkZkxsUWKRq9oegcCbwL+7++uDzVQDufnUszZ1BmofMrAHYBrR4hUwpKEg15PIFXujo4dCZk1i3vZMj507loQ072dbWzcrn28kVCpy4oNg+8eNHn6PgcNwh01nzQseY5rMpm+GwgyaTKxSY0tjAjMkN9OadvT05jmqZyt6ePF19eQ6dNZkZkxpo6+pjUmOWvnyBqc0NtExrpq2rj7nTmnh25z5+v34nV7xqMRt37GXezEnMnlLsCpzJGAV3CgWnMZthanOWxmyGghdnzd3R2cNBU5qY1Jhl975e5kxtpqkhw47OHlqmN9ObK7bbzJ7aRGdPjilNWWZObqStq48pTQ1MbsyytzeHB+1N4biUxmwmWoK2uSFDd1+B6ZOKnQlywfiVyY1ZuvryZKw4rXtvrhAsQVssoXX15ZnUkKXgTm++EL2H4noiuYLTkDF6Y9V+GaPuAu7+EBQuAc53978OPr8TOMPdPxBL82SQZnPweX2QZsdQx1VQkPHi7rR35cgVCuzrzbNw9hRWb23nyLlT2dHZQ3tXjt58geaGTDTF+NoXOqKb9vb2bjbu2MfDG3YWb2C5Ambw0sNmsuzZ3Wze3cXLF8/m4Q3F7rhHzi2OGZk/cxId3Tl27e1lb2+O9q4+Cg5zpzWXTHQ4cEbbkJnmg4r/DRoyhlMcBW/Rfou9D/7FIHrfvy9MabF9YYCJwoxRcuz+7w7YFjsOlEvXnxcz+MuXH8H7X3P0yP8AJA8KB0SXVDO7ArgC4PDDDx/n3Ei9MrNodto5wbYXzZ8BwIKDpsBBg79z2hFlNlbRwAkE8wWnJ5enMZuhJ3h6n9RYXDRp995epk9qYEdnDzMmN7Kjo5dpzQ20B4P9GrMZMgYdPTkmNWTpzRfo6cvT2ZOj4MU1wmdObqQvV6CxIUNPX56O7hz5grN7Xy9TmrLMmNwYnbOnr8DBM5rp6s2ztzdPwZ3OYLR5+FTflM0wrbmBnlyBfMFpyBZLEEZxEsZcwdnXm2dyY5Z8ISgJBCWhvlwh+tyTK5YCmhoydAUBOWMWlRh6cgWmNmVp6+ojkzEaYu1A7v0TKoaBw0ve928MY2v4MO0l2/rTDwzC7l4xXem+AXmJ5S98UKilWgaFLcDC2OcFwbZyaTYH1UczKTY4l3D3G4AboFhSqEluRQ5AA2eUzWb619hoDG64ofD9rKDK6ODppWt0iEBtRzQ/ChxjZkeaWRNwKXDzgDQ3A5cF7y8BflupPUFERGqrZiUFd8+Z2QeAOyl2Sf22u680s08Dy9z9ZuBG4L/NbB2wi2LgEBGRcVLTNgV3vx24fcC2T8TedwNvqWUeREQkOU2IJyIiEQUFERGJKCiIiEhEQUFERCIKCiIiEjngps42s1bg2ZRfnwsMOYXGBKVrrg+65vowmms+wt1bhkt0wAWF0TCzZUnm/phIdM31QddcH8bimlV9JCIiEQUFERGJ1FtQuGG8MzAOdM31QddcH2p+zXXVpiAiIpXVW0lBREQqqJugYGbnm9kaM1tnZleOd36qwcwWmtk9ZrbKzFaa2QeD7bPN7C4zWxv8e1Cw3czs68Hf4AkzO3V8ryA9M8ua2R/M7Nbg85Fm9khwbT8OpmvHzJqDz+uC/YvGM99pmdksM7vJzJ4ys9VmduZE/53N7O+D/66fNLMfmtmkifY7m9m3zWx7sApluG3Ev6uZXRakX2tml5U7V1J1ERTMLAt8E7gAOAF4u5mdML65qooc8GF3PwF4OfD+4LquBO5292OAu4PPULz+Y4LXFcC1Y5/lqvkgsDr2+QvAV9z9aGA3cHmw/XJgd7D9K0G6A9HXgF+5+/HASRSvfcL+zmZ2GPB3wBJ3fwnF6fcvZeL9zt8Bzh+wbUS/q5nNBj4JnAGcDnwyDCSpuPuEfwFnAnfGPl8FXDXe+arBdf4SeB2wBpgfbJsPrAneXw+8PZY+SncgvSiu4nc3cA5wK8UlbXcADQN/b4rreZwZvG8I0tl4X8MIr3cmsHFgvify7wwcBmwCZge/263A6yfi7wwsAp5M+7sCbweuj20vSTfSV12UFOj/Dyy0Odg2YQTF5VOAR4BD3H1rsGsbcEjwfqL8Hb4K/CNQCD7PAfa4e7hqffy6omsO9rfRv8TygeJIoBX4r6DK7FtmNpUJ/Du7+xbgS8BzwFaKv9tjTOzfOTTS37Wqv3e9BIUJzcymAT8FPuTu7fF9Xnx0mDBdzMzsYmC7uz823nkZQw3AqcC17n4KsJf+KgVgQv7OBwFvoBgQDwWmMriaZcIbj9+1XoLCFmBh7POCYNsBz8waKQaEH7j7z4LNL5jZ/GD/fGB7sH0i/B1eCfyZmT0D/IhiFdLXgFlmFq4kGL+u6JqD/TOBnWOZ4SrYDGx290eCzzdRDBIT+Xd+LbDR3VvdvQ/4GcXffiL/zqGR/q5V/b3rJSg8ChwT9FxoothgdfM452nUzMwornO92t2/HNt1MxD2QLiMYltDuP1dQS+GlwNtsWLqAcHdr3L3Be6+iOLv+Ft3/wvgHuCSINnAaw7/FpcE6Q+oJ2p33wZsMrPjgk3nAquYwL8zxWqjl5vZlOC/8/CaJ+zvHDPS3/VO4DwzOygoYZ0XbEtnvBtZxrAx50LgaWA98LHxzk+VruksikXLJ4DHg9eFFOtS7wbWAr8BZgfpjWIvrPXAHyn27Bj36xjF9Z8N3Bq8XwwsBdYBPwGag+2Tgs/rgv2LxzvfKa/1ZGBZ8Fv/Ajhoov/OwKeAp4Angf8Gmifa7wz8kGKbSR/FEuHlaX5X4K+Ca18HvGc0edKIZhERidRL9ZGIiCSgoCAiIhEFBRERiSgoiIhIREFBREQiCgoiY8jMzg5ndhXZHykoiIhIREFBpAwz+0szW2pmj5vZ9cH6DZ1m9pVgjv+7zawlSHuymT0czHH/89j890eb2W/MbIWZLTezo4LDT4utjfCDYMSuyH5BQUFkADN7EfA24JXufjKQB/6C4qRsy9z9xcC9FOewB/ge8E/ufiLFkabh9h8A33T3k4BXUBy5CsXZbD9EcW2PxRTn9BHZLzQMn0Sk7pwLnAY8GjzET6Y4KVkB+HGQ5vvAz8xsJjDL3e8Ntn8X+ImZTQcOc/efA7h7N0BwvKXuvjn4/DjF+fQfqP1liQxPQUFkMAO+6+5XlWw0+/iAdGnniOmJvc+j/w9lP6LqI5HB7gYuMbODIVoz9wiK/7+EM3S+A3jA3duA3Wb2J8H2dwL3unsHsNnM3hgco9nMpozpVYikoCcUkQHcfZWZ/TPwazPLUJzB8v0UF7c5Pdi3nWK7AxSnN74uuOlvAN4TbH8ncL2ZfTo4xlvG8DJEUtEsqSIJmVmnu08b73yI1JKqj0REJKKSgoiIRFRSEBGRiIKCiIhEFBRERCSioCAiIhEFBRERiSgoiIhI5P8DyUT9JLkkp7sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.arange(M) + 1, history.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('training loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, use the `.evaluate()` method on the test set (`x_test` and `y_test`) to get a sense of how our model will generalize to new data. The `.evaluate()` method returns two values: the first is loss and the second is accuracy. Save the results to variables `loss` and `accuracy` and print these results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  0.6159882545471191 Accuracy:  0.9049999713897705\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Loss: ', str(loss) , 'Accuracy: ', str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testlossacc\n",
    "try:\n",
    "    print(testlossacc(model, x_test, y_test, loss, accuracy))\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell below, make a prediction on our test data. We will later analyze for ourselves whether the prediction is accurate.\n",
    "\n",
    "1. Use the `.predict()` method to make a prediction on `x_test` and save the results to variable `1ogits`.\n",
    "\n",
    "2. Next, use method `.argmax(axis=1)` to convert `logits` to predicted labels, and save the results to variable `pred`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions for the first 5 data points:\n",
      "Logits\t\t\tClass\n",
      "[-7.282077   7.2656555]\t1\n",
      "[-3.1004603  3.0962598]\t1\n",
      "[-4.815721  4.804714]\t1\n",
      "[-1.1063694  1.0996342]\t1\n",
      "[-7.725144  7.719185]\t1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the network\n",
    "# Make predictions on the test set\n",
    "logits = model.predict(x_test)\n",
    "pred = logits.argmax(axis = 1)\n",
    "\n",
    "print(\"Predictions for the first 5 data points:\")\n",
    "print(\"Logits\\t\\t\\tClass\")\n",
    "for i in range(0,5):\n",
    "    print(str(logits[i]) + \"\\t\" + str(pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Self-Check\n",
    "Run the cell below to test the correctness of your code above before submitting for grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct!\n"
     ]
    }
   ],
   "source": [
    "# Run this self-test cell to check your code; do not add code or delete code in this cell\n",
    "from jn import testpred\n",
    "try:\n",
    "    print(testpred(model, x_test, logits, pred))\n",
    "except Exception as e:\n",
    "    print(\"Error!\\n\" + str(e))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To examine an individual test case we can print out the 20th row of the test data set and see how our model classified it. Remember that label 1 refers to a positive review and label 0 to a negative review. The code cell below prints out the review and the predicted lablel. How did we do on this one?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      "\n",
      "  I'm almost finished reading this book, and what a long, fun ride it's been.  Wordy, and a little confusing, this book has to be taken in the right mood, or else you'll miss the humor.\n",
      "\n",
      "The places that the main character travels to are memorable and exciting, and I found myself getting through a hefty portion, without thinking that I had ever started.\n",
      "\n",
      "Some....no, more like most of the satire is cryptic, and hard to find.  However, I read up on the book, and it immediately popped out at me, and made alot more sense.\n",
      "\n",
      "This is an excellent book, that I'm sure you will enjoy.  It might even suit as a read-aloud story for younger children\n",
      "\n",
      "\n",
      "Model prediction: \n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print('Input: \\n\\n ',review_test.iloc[20]['review'])\n",
    "\n",
    "label = pred[20]\n",
    "print('\\nModel prediction: ')\n",
    "if label == 1:\n",
    "    print('Positive')\n",
    "else:\n",
    "    print('Negative')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
